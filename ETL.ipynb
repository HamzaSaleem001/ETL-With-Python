{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import sqlite3\n",
    "from bs4 import BeautifulSoup\n",
    "from io import StringIO\n",
    "from datetime import datetime\n",
    "from icecream import ic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 0: Maintaining a Log File\n",
    "This step is done to record the logs while performing ETL and it is not neccessary in an ETL Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Logs(Message):\n",
    "    \"\"\"This function logs the mentioned message of a given stage of the\n",
    "    code execution to a log file. Function returns nothing\"\"\"\n",
    "\n",
    "    try:\n",
    "        with open('./Log/code_log.txt' , 'a') as file:\n",
    "            file.write(f'{datetime.now()} : {Message}\\n')\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract(URL , Table_Attribute):\n",
    "    \"\"\" This function aims to extract the required\n",
    "    information from the website and save it to a data frame. The\n",
    "    function returns the data frame for further processing. \"\"\"\n",
    "    try:\n",
    "        Soup = BeautifulSoup(requests.get(URL).text , 'html.parser')\n",
    "        Table = Soup.find('span' , string=Table_Attribute).find_next('table')\n",
    "        Data = pd.read_html(StringIO(str(Table)))[0]\n",
    "\n",
    "        Logs('Data extraction complete. Initiating Transformation process')\n",
    "        return Data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        Logs('Data extraction Incomplete.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Transformation(Data , CSV_Path):\n",
    "    \"\"\" This function accesses the CSV file for exchange rate\n",
    "    information, and adds three columns to the data frame, each\n",
    "    containing the transformed version of Market Cap column to\n",
    "    respective currencies\"\"\"\n",
    "\n",
    "    try:\n",
    "        Exachange_rate = pd.read_csv(CSV_Path , index_col=0).to_dict()['Rate']\n",
    "\n",
    "        Data['Market cap EUR billion'] = round(Data['Market cap (US$ billion)'] * Exachange_rate['EUR'],2)\n",
    "        Data['Market cap GBP billion'] = round(Data['Market cap (US$ billion)'] * Exachange_rate['GBP'],2)\n",
    "        Data['Market cap INR billion'] = round(Data['Market cap (US$ billion)'] * Exachange_rate['INR'],2)\n",
    "        Data['Market cap PKR billion'] = round(Data['Market cap (US$ billion)'] * Exachange_rate['PKR'],2)\n",
    "\n",
    "        Logs('Data transformation complete. Initiating Loading process')\n",
    "\n",
    "        return Data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        Logs('Data transformation Incomplete')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data to a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load(Data , Output_Path):\n",
    "    \"\"\" This function saves the final data frame as a CSV file in\n",
    "    the provided path. Function returns nothing.\"\"\"\n",
    "    try:\n",
    "        Data.to_csv(Output_Path)\n",
    "\n",
    "        Logs('Data saved to CSV file')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        Logs('Data Not saved to CSV file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data to SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_TO_DB(Data , sql_connection , table_Name):\n",
    "    \"\"\" This function saves the final data frame to a database\n",
    "    table with the provided name. Function returns nothing.\"\"\"\n",
    "\n",
    "    try:\n",
    "        Data.to_sql(table_Name , sql_connection  , index = False)\n",
    "\n",
    "        Logs('Data loaded to Database as a table, Executing queries')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        Logs('Data Not Loaded to Database')\n",
    "    \n",
    "def Run_Query(Query , sql_connection):\n",
    "    try:\n",
    "        cursor = sql_connection.cursor()\n",
    "        cursor.execute(Query)\n",
    "        Result = cursor.fetchall()       \n",
    "        Logs('Process Complete')       \n",
    "        return Result\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        Logs('Process Incomplete')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    URL = 'https://web.archive.org/web/20230908091635/https://en.wikipedia.org/wiki/List_of_largest_banks'\n",
    "    Output_Path = './Output/Largest_Banks_Data.csv'\n",
    "    DataBase = './Output/Banks.db'\n",
    "    table_Name = 'Largest_Bank'\n",
    "    Table_Attribute = 'By market capitalization'\n",
    "    CSV_Path = './Input/exchange_rate.csv'\n",
    "\n",
    "    try:\n",
    "        Data = Extract(URL ,  Table_Attribute)\n",
    "\n",
    "        Transformation(Data , CSV_Path)\n",
    "\n",
    "        #Load To CSV\n",
    "        Load(Data , Output_Path)\n",
    "\n",
    "        #Load to DB\n",
    "        with sqlite3.connect(DataBase) as sql_connection:\n",
    "            Load_TO_DB(Data , sql_connection , table_Name)\n",
    "\n",
    "            print(Run_Query('select * from Largest_Bank' , sql_connection))\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
